{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3221831f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.18.5 in c:\\users\\9029\\anaconda3\\lib\\site-packages (1.18.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --user numpy==1.18.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be710467",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/66207609/notimplementederror-cannot-convert-a-symbolic-tensor-lstm-2-strided-slice0-t\n",
    "\n",
    "##### Versioning issue when building keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61438d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models, preprocessing\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1196754",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 10000\n",
    "(training_features, training_labels) , (testing_features, testing_labels) = datasets.imdb.load_data(num_words = VOCAB_SIZE)\n",
    "\n",
    "#num_words*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf500c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "618cda27",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 250\n",
    "\n",
    "training_features = preprocessing.sequence.pad_sequences(training_features, length)\n",
    "testing_features = preprocessing.sequence.pad_sequences(testing_features, length)\n",
    "\n",
    "#ensuring each data is the same length.. , padding head with zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6d4a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5b68ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 32)          320000    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 328,353\n",
      "Trainable params: 328,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Embedding(VOCAB_SIZE,32))\n",
    "model.add(layers.LSTM(32))\n",
    "model.add(layers.Dense(1,activation = 'sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e5c69ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"rmsprop\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ea8f1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 38s 61ms/step - loss: 0.4147 - accuracy: 0.8191 - val_loss: 0.3255 - val_accuracy: 0.8600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24ca1618b20>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_features, training_labels, epochs=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92b477c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 14s 18ms/step - loss: 0.3303 - accuracy: 0.8575\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3303106129169464, 0.8575199842453003]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(testing_features, testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b266a4ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88584"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index = datasets.imdb.get_word_index()\n",
    "len(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0636a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0 17  6 63 84]\n"
     ]
    }
   ],
   "source": [
    "def encode_text(text):\n",
    "    tokens = keras.preprocessing.text.text_to_word_sequence(text)\n",
    "    tokens = [word_index[word] if word in word_index else 0 for word in tokens]\n",
    "    return preprocessing.sequence.pad_sequences([tokens], length)[0]\n",
    "\n",
    "text = \"movie is really great\"\n",
    "encoded = encode_text(text)\n",
    "print(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "440f59c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05690649]\n"
     ]
    }
   ],
   "source": [
    "def predict(text):\n",
    "    encoded_text = encode_text(text)\n",
    "    pred = np.zeros((1,length))\n",
    "    pred[0] = encoded_text\n",
    "    result = model.predict(pred) \n",
    "    print(result[0])\n",
    "\n",
    "positive_review = \"The movie is awesome and great! I would love to watch it again and again.\"\n",
    "predict(positive_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31645c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
