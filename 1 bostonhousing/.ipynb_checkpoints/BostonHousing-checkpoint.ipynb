{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5b4ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4077d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "(training_features, training_labels), (testing_features, testing_labels) = datasets.boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3a6388",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler() #Instantiate a scaler object\n",
    "scaler.fit(training_features) #Computes mean and sd for this particular scaler instance to be used below\n",
    "training_features_scaled = scaler.transform(training_features)\n",
    "testing_features_scaled = scaler.transform(testing_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2981a285",
   "metadata": {},
   "source": [
    "## FEATURE SCALING IS VERY IMPORTANT\n",
    "\n",
    "#### https://towardsdatascience.com/all-about-feature-scaling-bcc0ad75cb35\n",
    "\n",
    "#### \"Machine learning algorithm just sees numbers â€” if there is a vast difference in the range say few ranging in thousands and few ranging in the tens, and it makes the underlying assumption that higher ranging numbers have superiority of some sort. So these more significant number starts playing a more decisive role while training the model.\"\n",
    "\n",
    "#### \"Most of the times, your dataset will contain features highly varying in magnitudes, units and range. But since, most of the machine learning algorithms use Eucledian distance between two data points in their computations, this is a problem. If left alone, these algorithms only take in the magnitude of features neglecting the units. The results would vary greatly between different units, 5kg and 5000gms. The features with high magnitudes will weigh in a lot more in the distance calculations than features with low magnitudes.\n",
    "\n",
    "#### \"Another reason why feature scaling is applied is that few algorithms like Neural network gradient descent converge much faster with feature scaling than without it.\"\n",
    "\n",
    "#### Normalization is used when we want to bound our values between two numbers, typically, between [0,1] or [-1,1]. While Standardization transforms the data to have zero mean and a variance of 1,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b2b5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93d8904",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features_scaled[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e5385c",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_features_scaled.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68c8f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "model.add(layers.Dense(32,activation = 'relu', input_shape = [13]))\n",
    "#input shape should be the 13 parameters linearly and needs to be in a tuple or list\n",
    "\n",
    "model.add(layers.Dense(16,activation = 'relu'))\n",
    "\n",
    "model.add(layers.Dense(1)) #Single output node to predict one single numerical value\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(),loss=keras.losses.mse)\n",
    "#getting optimizers need to have the () but losses don't need.\n",
    "#metrics parameter accepts a list of keywords to show additional parameter output at each epoch\n",
    "#adagrad, adadelta, ftrl has high loss but not adam, RMSprop\n",
    "\n",
    "letsgo = model.fit(training_features_scaled, training_labels, validation_split=0.1, epochs=200, verbose = 0)\n",
    "# validation split is the percentage of testing data to be set aside for validation 0.1 = 10%\n",
    "# epochs is number of times going through entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d314cf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( model.predict(testing_features_scaled[50:60]), '\\n' ) #predictions\n",
    "print( testing_labels[50:60], '\\n') #actual values\n",
    "print(model.evaluate(testing_features_scaled,testing_labels)) #display loss value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce4d4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = keras.Sequential()\n",
    "\n",
    "model2.add(layers.Dense(32,activation = 'relu', input_shape = [13]))\n",
    "# input shape should be the 13 parameters linearly and needs to be in a tuple,list or simpler array like structure\n",
    "\n",
    "model2.add(layers.Dense(16,activation = 'relu'))\n",
    "\n",
    "model2.add(layers.Dense(1)) #Single output node to predict one single numerical value\n",
    "\n",
    "model2.compile(optimizer=keras.optimizers.Adam(),loss=keras.losses.mse)\n",
    "\n",
    "letsgo2 = model.fit(training_features, training_labels, validation_split=0.1, epochs=200, verbose = 0)\n",
    "#Lack of scaling makes the model not as good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1a987d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( model2.predict(testing_features[50:60]), '\\n' ) #predictions\n",
    "print( testing_labels[50:60], '\\n') #actual values\n",
    "print(model2.evaluate(testing_features,testing_labels)) #display loss value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
