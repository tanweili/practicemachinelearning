{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c73a69bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c052cf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "(training_features, training_labels) , (testing_features, testing_labels) = datasets.cifar100.load_data(label_mode='fine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75b0eb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features_scaled, testing_features_scaled = training_features / 255.0, testing_features / 255.0\n",
    "#Original training features and testing features are integer arrays, scaling and converting to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8a99d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_NAMES = ['apple','aquarium_fish','baby','bear','beaver','bed','bee','beetle','bicycle','bottle','bowl','boy','bridge',\n",
    "'bus','butterfly','camel','can','castle','caterpillar','cattle','chair','chimpanzee','clock','cloud','cockroach','couch',\n",
    "'crab','crocodile','cup','dinosaur','dolphin','elephant','flatfish','forest','fox','girl','hamster','house','kangaroo',\n",
    "'keyboard','lamp','lawn_mower','leopard','lion','lizard','lobster','man','maple_tree','motorcycle','mountain','mouse',\n",
    "'mushroom','oak_tree','orange','orchid','otter','palm_tree','pear','pickup_truck','pine_tree','plain','plate','poppy',\n",
    "'porcupine','possum','rabbit','raccoon','ray','road','rocket','rose','sea','seal','shark','shrew','skunk','skyscraper',\n",
    "'snail','snake','spider','squirrel','streetcar','sunflower','sweet_pepper','table','tank','telephone','television','tiger',\n",
    "'tractor','train','trout','tulip','turtle','wardrobe','whale','willow_tree','wolf','woman','worm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012ab433",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88439b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 30, 30, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 10816)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               5538304   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               51300     \n",
      "=================================================================\n",
      "Total params: 5,628,324\n",
      "Trainable params: 5,628,324\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "#Conv layer\n",
    "model.add(layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "#model.add(layers.MaxPooling2D((2, 2)))\n",
    "#model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "#Dense layer\n",
    "model.add(layers.Flatten()) #need to make the layer linear to connect to Dense layers\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(100))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084e5a41",
   "metadata": {},
   "source": [
    "##### Seems like ReLU preferred for images analysis? Also cannot use too many layers or number per layer.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36286d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(),loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "             , metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "#need to use SparseCategoricalAccuracyinstead of other types of accuracies.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b942f356",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = model.fit(training_features_scaled,training_labels,epochs=1,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86bc120",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(testing_features_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d057602",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(index):\n",
    "    plt.imshow( testing_features[index] )\n",
    "    print(\"The actual picture is a \" +LABEL_NAMES[ int( testing_labels[index] ) ] )\n",
    "    print(\"The predicted picture is a \" +LABEL_NAMES[predictions[index].argmax()])\n",
    "    \n",
    "prediction(4862)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa18764",
   "metadata": {},
   "source": [
    "### Using pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87398006",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = keras.applications.VGG16(input_shape=[32, 32, 3],include_top=False,weights='imagenet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923e88db",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.summary()\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330e4911",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_average_layer = keras.layers.GlobalAveragePooling2D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779946e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_layer = keras.layers.Dense(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662bd66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = keras.Sequential([base_model,global_average_layer,prediction_layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e845504",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer=keras.optimizers.Adam(),\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20afb361",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d02655",
   "metadata": {},
   "outputs": [],
   "source": [
    "letsgo = model2.fit(training_features_scaled,training_labels,epochs=1,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0193612",
   "metadata": {},
   "source": [
    "Epoch 1/10\n",
    "1407/1407 [==============================] - 16s 10ms/step - loss: 3.4285 - accuracy: 0.2109 - val_loss: 3.0777 - val_accuracy: 0.2640\n",
    "Epoch 2/10\n",
    "1407/1407 [==============================] - 13s 9ms/step - loss: 2.8858 - accuracy: 0.2970 - val_loss: 2.8968 - val_accuracy: 0.2988\n",
    "Epoch 3/10\n",
    "1407/1407 [==============================] - 13s 9ms/step - loss: 2.7181 - accuracy: 0.3304 - val_loss: 2.8238 - val_accuracy: 0.3084\n",
    "Epoch 4/10\n",
    "1407/1407 [==============================] - 13s 9ms/step - loss: 2.6139 - accuracy: 0.3488 - val_loss: 2.7588 - val_accuracy: 0.3226\n",
    "Epoch 5/10\n",
    "1407/1407 [==============================] - 13s 9ms/step - loss: 2.5398 - accuracy: 0.3632 - val_loss: 2.7394 - val_accuracy: 0.3294\n",
    "Epoch 6/10\n",
    "1407/1407 [==============================] - 13s 9ms/step - loss: 2.4810 - accuracy: 0.3748 - val_loss: 2.7017 - val_accuracy: 0.3384\n",
    "Epoch 7/10\n",
    "1407/1407 [==============================] - 13s 9ms/step - loss: 2.4334 - accuracy: 0.3848 - val_loss: 2.6841 - val_accuracy: 0.3406\n",
    "Epoch 8/10\n",
    "1407/1407 [==============================] - 13s 9ms/step - loss: 2.3923 - accuracy: 0.3914 - val_loss: 2.6799 - val_accuracy: 0.3388\n",
    "Epoch 9/10\n",
    "1407/1407 [==============================] - 14s 10ms/step - loss: 2.3581 - accuracy: 0.3989 - val_loss: 2.6522 - val_accuracy: 0.3484\n",
    "Epoch 10/10\n",
    "1407/1407 [==============================] - 13s 9ms/step - loss: 2.3270 - accuracy: 0.4051 - val_loss: 2.6533 - val_accuracy: 0.3486"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225b40e1",
   "metadata": {},
   "source": [
    "##### Low accuracy compared to my simple model built from scratch.., perhaps too many conv / pooling layers for simple 32x32 pixel pictures? Maybe if picture is higher resolution then accuracy would be higher using pretrained models with many layers like the VGG16"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
